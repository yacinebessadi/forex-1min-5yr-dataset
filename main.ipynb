{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf227a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb0c9886",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_to_merge = [\n",
    "    \"EURUSD_1m_raw_2020-11-22_2020-12-31.csv\",\n",
    "    \"EURUSD_1m_raw_2021-01-01_2021-12-31.csv\",\n",
    "    \"EURUSD_1m_raw_2022-01-01_2022-12-31.csv\",\n",
    "    \"EURUSD_1m_raw_2023-01-01_2023-12-31.csv\",\n",
    "    \"EURUSD_1m_raw_2024-01-01_2024-12-31.csv\",\n",
    "    \"EURUSD_1m_raw_2025-01-01_2025-11-21.csv\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed29b5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file EURUSD_1m_raw_2020-11-22_2020-12-31.csv loaded, shape: (40622, 6)\n",
      "file EURUSD_1m_raw_2021-01-01_2021-12-31.csv loaded, shape: (370681, 6)\n",
      "file EURUSD_1m_raw_2022-01-01_2022-12-31.csv loaded, shape: (372879, 6)\n",
      "file EURUSD_1m_raw_2023-01-01_2023-12-31.csv loaded, shape: (371105, 6)\n",
      "file EURUSD_1m_raw_2024-01-01_2024-12-31.csv loaded, shape: (372798, 6)\n",
      "file EURUSD_1m_raw_2025-01-01_2025-11-21.csv loaded, shape: (333186, 6)\n"
     ]
    }
   ],
   "source": [
    "for file in files_to_merge:\n",
    "    df_temp=pd.read_csv(file)\n",
    "    print(f\"file {file} loaded, shape: {df_temp.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d54d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files merged, final shape: (1861271, 6)\n"
     ]
    }
   ],
   "source": [
    "dfs=[pd.read_csv(f) for f in files_to_merge]\n",
    "df=pd.concat(dfs, ignore_index=True)\n",
    "print(f\"All files merged, final shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d45cd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-22 22:00:00+00:00\n",
      "2025-11-21 21:59:00+00:00\n"
     ]
    }
   ],
   "source": [
    "print(df['timestamp'].iloc[0])\n",
    "print(df['timestamp'].iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851eb67",
   "metadata": {},
   "source": [
    "last value here is 21 Nov 2025 because 22 Nov was a saturday hence 0 raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c449bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-22 22:00:00+00:00</td>\n",
       "      <td>1.18538</td>\n",
       "      <td>1.18547</td>\n",
       "      <td>1.18537</td>\n",
       "      <td>1.18541</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-22 22:01:00+00:00</td>\n",
       "      <td>1.18540</td>\n",
       "      <td>1.18542</td>\n",
       "      <td>1.18537</td>\n",
       "      <td>1.18541</td>\n",
       "      <td>26.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp     open     high      low    close  volume\n",
       "0  2020-11-22 22:00:00+00:00  1.18538  1.18547  1.18537  1.18541   10.50\n",
       "1  2020-11-22 22:01:00+00:00  1.18540  1.18542  1.18537  1.18541   26.25"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#renaming the columns as required\n",
    "df = df.rename(columns={\n",
    "    \"UTC\": \"timestamp\",\n",
    "    \"Open\": \"open\",\n",
    "    \"High\": \"high\",\n",
    "    \"Low\": \"low\",\n",
    "    \"Close\": \"close\",\n",
    "    \"Volume\": \"volume\",\n",
    "})\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6870415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bessa\\AppData\\Local\\Temp\\ipykernel_9960\\3512892983.py:2: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S%z format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True, dayfirst=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-22 22:00:00+00:00</td>\n",
       "      <td>1.18538</td>\n",
       "      <td>1.18547</td>\n",
       "      <td>1.18537</td>\n",
       "      <td>1.18541</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-11-22 22:01:00+00:00</td>\n",
       "      <td>1.18540</td>\n",
       "      <td>1.18542</td>\n",
       "      <td>1.18537</td>\n",
       "      <td>1.18541</td>\n",
       "      <td>26.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp     open     high      low    close  volume\n",
       "0 2020-11-22 22:00:00+00:00  1.18538  1.18547  1.18537  1.18541   10.50\n",
       "1 2020-11-22 22:01:00+00:00  1.18540  1.18542  1.18537  1.18541   26.25"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parsing timestamp to UTC datetime\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], utc=True, dayfirst=True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b7844e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min 2020-11-22 22:00:00+00:00, max 2025-11-21 21:59:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# 2) Sort and drop duplicate timestamps\n",
    "df = df.sort_values(\"timestamp\").drop_duplicates(subset=[\"timestamp\"]).reset_index(drop=True)\n",
    "print(f\"min {df['timestamp'].min()}, max {df['timestamp'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e3c0886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_index length: 2628000\n",
      "df index length  : 2628000\n",
      "2020-11-22 22:00:00+00:00 2025-11-21 21:59:00+00:00\n"
     ]
    }
   ],
   "source": [
    "# Build expected 1‑minute continuous interval\n",
    "full_index = pd.date_range(\n",
    "    start=df[\"timestamp\"].min(),\n",
    "    end=df[\"timestamp\"].max(),\n",
    "    freq=\"min\",   # 1 minute\n",
    "    tz=\"UTC\",\n",
    ")\n",
    "# Reindex onto this grid\n",
    "df = df.set_index(\"timestamp\").reindex(full_index)\n",
    "\n",
    "print(\"full_index length:\", len(full_index))\n",
    "print(\"df index length  :\", len(df))\n",
    "print(df.index.min(), df.index.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "185a0d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missing_bar\n",
       "False    1861271\n",
       "True      766729\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"missing_bar\"] = df[\"open\"].isna()\n",
    "df[\"missing_bar\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e48bbcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earliest timestamp: 2020-11-22 22:00:00+00:00\n",
      "Latest timestamp : 2025-11-21 21:59:00+00:00\n",
      "Expected 1m bars : 2628000\n",
      "Actual raw bars  : 1861271\n",
      "Missing minutes filled (missing_bar=True): 766729\n"
     ]
    }
   ],
   "source": [
    "# Gap summary values \n",
    "earliest = df.index.min()   # timestamp is the index\n",
    "latest = df.index.max()\n",
    "expected = len(df)          # 1861271 continuous minutes\n",
    "actual = (df[\"missing_bar\"] == False).sum()  # 2628000 real bars\n",
    "filled = (df[\"missing_bar\"] == True).sum()   # 766729 synthetic bars\n",
    "\n",
    "print(\"Earliest timestamp:\", earliest)\n",
    "print(\"Latest timestamp :\", latest)\n",
    "print(\"Expected 1m bars :\", expected)\n",
    "print(\"Actual raw bars  :\", actual)\n",
    "print(\"Missing minutes filled (missing_bar=True):\", filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4929b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save original missing timestamps to a text file (before fill)\n",
    "missing_ts = df.index[df[\"missing_bar\"] == True]\n",
    "missing_ts.to_series().dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\").to_csv(\n",
    "    \"EURUSD_1m_UTC_2020-11-22_2025-11-21_missing_timestamps.txt\",\n",
    "    index=False,\n",
    "    header=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eec15883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing minutes using prior bar's OHLCV (ffill)\n",
    "df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]] = (\n",
    "    df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]].ffill()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "26bf0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index().rename(columns={\"index\": \"timestamp\"})\n",
    "df = df[df[\"timestamp\"].dt.dayofweek < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60c1de68-bbb5-4163-b4b4-39375e4e09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Format to ISO8601 UTC string\n",
    "df[\"timestamp\"] = df[\"timestamp\"].dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b596f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enforce final order\n",
    "cols = [\"timestamp\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"missing_bar\"]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71a9da",
   "metadata": {},
   "source": [
    "This dataset uses Dukascopy EURUSD 1‑minute data for a rolling 5‑year window,\n",
    "Raw downloads request to 2025-11-22 23:59\n",
    "but Dukascopy provides up to Friday 2025-11-21 21:59 market close (Saturday exclude), aligned to a continuous 1‑minute UTC grid between the earliest and latest timestamp in the raw download.\n",
    "Timestamps were parsed as UTC, sorted, deduplicated, and aligned to this continuous 1‑minute grid. Missing minutes were filled using the prior bar’s OHLCV values (ffill), and a missing_bar boolean column flags all synthetic bars created by this procedure, following the “fill missing minutes using prior close + missing_bar” option in the brief. Weekend rows (Saturday and Sunday) were removed from the final delivered file, while preserving the gap statistics on trading days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28cca6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final 5‑year EURUSD csv\n",
    "output_path = \"EURUSD_1m_UTC_2020-11-22_2025-11-21.csv\"\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014f0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metadata json \n",
    "import json\n",
    "\n",
    "df_final = pd.read_csv(\"EURUSD_1m_UTC_2020-11-22_2025-11-21.csv\")\n",
    "\n",
    "final_total = len(df_final)  # 1,879,080\n",
    "final_filled = (df_final[\"missing_bar\"] == True).sum()  # 57,688\n",
    "\n",
    "# Update metadata\n",
    "meta = {\n",
    "    \"pair\": \"EURUSD\",\n",
    "    \"from\": \"2020-11-22T22:00:00Z\",\n",
    "    \"to\": \"2025-11-21T21:59:00Z\",\n",
    "    \"total_rows\": int(final_total),\n",
    "    \"missing_bars\": int(final_filled),\n",
    "    \"source\": \"Dukascopy\",\n",
    "    \"note\": (\n",
    "        \"Rolling 5-year weekday-only data (Sat/Sun excluded); \"\n",
    "        \"missing weekday minutes forward-filled and flagged via missing_bar.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "with open(\"EURUSD_1m_UTC_2020-11-22_2025-11-21_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b835934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Metadata updated to match file.\n"
     ]
    }
   ],
   "source": [
    "# Update gap summary\n",
    "summary = f\"\"\"EURUSD 1-minute Dukascopy (UTC)\n",
    "\n",
    "Coverage:\n",
    "- From: 2020-11-22 22:00:00 UTC\n",
    "- To  : 2025-11-21 21:59:00 UTC\n",
    "\n",
    "Counts (Weekdays Only):\n",
    "- Total rows in file: {final_total}\n",
    "- Real bars: {final_total - final_filled}\n",
    "- Filled bars: {final_filled}\n",
    "\n",
    "Notes:\n",
    "- Weekends excluded.\n",
    "- Missing weekday minutes forward-filled.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(\"EURUSD_1m_UTC_2020-11-22_2025-11-22_gap_summary.txt\", \"w\") as f:\n",
    "    f.write(summary)\n",
    "\n",
    "print(\"✓ Metadata updated to match file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3044bc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EURUSD 5-Year Dataset Validation ===\n",
      "\n",
      "File outputs:\n",
      "  EURUSD_1m_UTC_2020-11-22_2025-11-21.csv: ✓\n",
      "  EURUSD_1m_UTC_2020-11-22_2025-11-21_gap_summary.txt: ✓\n",
      "  EURUSD_1m_UTC_2020-11-22_2025-11-21_meta.json: ✓\n",
      "  EURUSD_1m_UTC_2020-11-22_2025-11-21_missing_timestamps.txt: ✓\n",
      "\n",
      "CSV shape: (1879080, 7)\n",
      "Columns: ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'missing_bar']\n",
      "First row timestamp: 2020-11-23T00:00:00Z\n",
      "Last row timestamp: 2025-11-21T21:59:00Z\n",
      "\n",
      "Data composition:\n",
      "  Real bars (missing_bar=False): 1821392\n",
      "  Synthetic bars (missing_bar=True): 57688\n",
      "  Total rows: 1879080\n",
      "  NaN values in OHLCV: 0\n",
      "\n",
      "Metadata:\n",
      "  Pair: EURUSD\n",
      "  From: 2020-11-22T22:00:00Z\n",
      "  To: 2025-11-21T21:59:00Z\n",
      "  Total rows: 1879080\n",
      "  Missing bars: 57688\n",
      "  Source: Dukascopy\n",
      "\n",
      "✓ EURUSD 5-year build complete and validated.\n"
     ]
    }
   ],
   "source": [
    "# Quick validation check after weekend filter\n",
    "\n",
    "print(\"=== EURUSD 5-Year Dataset Validation ===\\n\")\n",
    "\n",
    "# 1. File check\n",
    "import os\n",
    "files_expected = [\n",
    "    \"EURUSD_1m_UTC_2020-11-22_2025-11-21.csv\",\n",
    "    \"EURUSD_1m_UTC_2020-11-22_2025-11-21_gap_summary.txt\",\n",
    "    \"EURUSD_1m_UTC_2020-11-22_2025-11-21_meta.json\",\n",
    "    \"EURUSD_1m_UTC_2020-11-22_2025-11-21_missing_timestamps.txt\",\n",
    "]\n",
    "print(\"File outputs:\")\n",
    "for f in files_expected:\n",
    "    exists = \"✓\" if os.path.exists(f) else \"✗ MISSING\"\n",
    "    print(f\"  {f}: {exists}\")\n",
    "\n",
    "# 2. CSV integrity\n",
    "df_final = pd.read_csv(\"EURUSD_1m_UTC_2020-11-22_2025-11-21.csv\")\n",
    "print(f\"\\nCSV shape: {df_final.shape}\")\n",
    "print(f\"Columns: {df_final.columns.tolist()}\")\n",
    "print(f\"First row timestamp: {df_final['timestamp'].iloc[0]}\")\n",
    "print(f\"Last row timestamp: {df_final['timestamp'].iloc[-1]}\")\n",
    "\n",
    "# 3. Data quality\n",
    "weekday_count = df_final[df_final['missing_bar'] == False].shape[0]\n",
    "synthetic_count = df_final[df_final['missing_bar'] == True].shape[0]\n",
    "print(f\"\\nData composition:\")\n",
    "print(f\"  Real bars (missing_bar=False): {weekday_count}\")\n",
    "print(f\"  Synthetic bars (missing_bar=True): {synthetic_count}\")\n",
    "print(f\"  Total rows: {len(df_final)}\")\n",
    "print(f\"  NaN values in OHLCV: {df_final[['open','high','low','close','volume']].isna().sum().sum()}\")\n",
    "\n",
    "# 4. Metadata check\n",
    "import json\n",
    "with open(\"EURUSD_1m_UTC_2020-11-22_2025-11-21_meta.json\") as f:\n",
    "    meta = json.load(f)\n",
    "print(f\"\\nMetadata:\")\n",
    "print(f\"  Pair: {meta['pair']}\")\n",
    "print(f\"  From: {meta['from']}\")\n",
    "print(f\"  To: {meta['to']}\")\n",
    "print(f\"  Total rows: {meta['total_rows']}\")\n",
    "print(f\"  Missing bars: {meta['missing_bars']}\")\n",
    "print(f\"  Source: {meta['source']}\")\n",
    "\n",
    "print(\"\\n✓ EURUSD 5-year build complete and validated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a2e979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8dd9c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
